strategy: ddp
benchmark: true
deterministic: false
pretrained: false
sync_batchnorm: false
clip_grad: null
precision: 32
max_steps: &max_steps 20000
val_check_interval: 1000
limit_val_batches: 100

# --------------------------------------
# Dataset parameters
# --------------------------------------
train_dataset:
  name: 'H36MDataset'
  params:
    data_root: &data_root '/data/shared/H36M-Toolbox'
    modality_names: ['rgb', 'depth']
    cameras: ['01','02','03','04']
    split: "train"
    seq_len: 1       
    seq_step: 1
    pad_seq: true
    causal: true
val_dataset:
  name: 'H36MDataset'
  params:
    data_root: *data_root
    modality_names: ['rgb', 'depth']
    cameras: ['01','02','03','04']
    split: "test"
    seq_len: 1
    seq_step: 1
    pad_seq: true
    causal: true
test_dataset:
  name: 'H36MDataset'
  params:
    data_root: *data_root
    modality_names: ['rgb', 'depth']
    cameras: ['01','02','03','04']
    split: "test"
    seq_len: 1
    seq_step: 1
    pad_seq: true
    causal: true
# --------------------------------------
# Optimizer parameters
# --------------------------------------
optim_name: AdamW
optim_params:
  lr: &lr 0.0001
  weight_decay: 0.00001
# --------------------------------------
# Learning rate scheduler parameters
# --------------------------------------
sched_name: OneCycleLR
sched_params:
  max_lr: *lr
  total_steps: *max_steps
  pct_start: 0.01  # 1% warmup (1000 steps)
  anneal_strategy: 'cos'
  div_factor: 10.0  # start_lr = max_lr / div_factor
  final_div_factor: 10000.0  # min_lr = max_lr / final_div_factor
# --------------------------------------
# Model parameters
# --------------------------------------
model_name: TestModel_1208
backbone_rgb:
  name: 'TimmWrapper'
  params:
    model_name: 'vit_small_patch16_dinov3'
    pretrained: true
  has_temporal: false
backbone_depth:
  name: 'TimmWrapper'
  params:
    model_name: 'vit_small_patch16_dinov3'
    pretrained: true
  has_temporal: false
aggregator:
  name: 'TransformerAggregator'
  params:
    input_dims: [384, 384, 512, 512]
    embed_dim: 256
    num_register_tokens: 4
    aa_order: ['single', 'global', 'cross']
    aa_block_size: 1
    depth: 6
    block_type: 'Block'
    num_heads: 8
    mlp_ratio: 2.0
    qkv_bias: true
    proj_bias: true
    ffn_bias: true
    qk_norm: true
    init_values: 0.01
keypoint_head:
  name: 'RegressionKeypointHead'
  params:
    emb_size: 768
    num_classes: 51
    losses:
      - name: 'MSELoss'
        params: null
        weight: 1.0
camera_head:
  name: 'RegressionCameraHead'
  params:
    emb_size: 768
    num_params: 9
    weight_trans: 1.0
    weight_rot: 1.0
    weight_focal: 0.5
    losses:
      - name: 'L1Loss'
        params: null
        weight: 1.0
# --------------------------------------
# Metrics parameters
# --------------------------------------
metrics:
  - name: 'MPJPE'
    params:
      affix: null
  - name: 'PAMPJPE'
    params:
      affix: null
# TODO: create metric for camera error
# --------------------------------------
# Augmentation parameters
# --------------------------------------
train_pipeline: &train_pipeline
  - name: VideoResize
    params:
      size: [256, 256]
      keep_ratio: false
      keys: ['input_rgb', 'input_depth']
  - name: VideoNormalize
    params:
      norm_mode: 'imagenet'
      keys: ['input_rgb']
  - name: VideoNormalize
    params:
      norm_mode: 'zero_one'
      keys: ['input_depth']
  - name: ToTensor
    params: null
  - name: CameraParamToPoseEncoding
    params: null
val_pipeline: *train_pipeline
test_pipeline: *train_pipeline
