strategy: ddp
benchmark: true
deterministic: false
pretrained: false
sync_batchnorm: false
clip_grad: null
precision: 16
epochs: &epochs 20
# --------------------------------------
# Dataset parameters
# --------------------------------------
train_dataset:
  name: 'MMFiPreprocessedDataset'
  params:
    data_root: &data_root 'data/mmfi'
    modality_names: ['rgb', 'depth', 'lidar', 'mmwave']
    split_config: &split_config 'configs/datasets/mmfi_split_config.yml'
    split_to_use: &split_to_use 'manual_split'
    protocol: &protocol 'protocol3'
    seq_len: 1
    seq_step: 1
    pad_seq: true
    causal: true
    test_mode: false
val_dataset:
  name: 'MMFiPreprocessedDataset'
  params:
    data_root: *data_root
    modality_names: ['rgb', 'depth', 'lidar', 'mmwave']
    split_config: *split_config
    split_to_use: *split_to_use
    protocol: *protocol
    seq_len: 1
    seq_step: 1
    pad_seq: true
    causal: true
    test_mode: true
test_dataset:
  name: 'MMFiPreprocessedDataset'
  params:
    data_root: *data_root
    modality_names: ['rgb', 'depth', 'lidar', 'mmwave']
    split_config: *split_config
    split_to_use: *split_to_use
    protocol: *protocol
    seq_len: 1
    seq_step: 1
    pad_seq: true
    causal: true
    test_mode: true
# --------------------------------------
# Optimizer parameters
# --------------------------------------
optim_name: AdamW
optim_params:
  lr: &lr 0.0001
  weight_decay: 0.0001  # Increased for better regularization
# --------------------------------------
# Learning rate scheduler parameters
# --------------------------------------
sched_name: LinearWarmupCosineAnnealingLR
sched_params:
  warmup_epochs: 2
  max_epochs: *epochs
  warmup_start_lr: 0.00001
  eta_min: 0.00001
# --------------------------------------
# Model parameters
# --------------------------------------
model_name: TestModel_V3
backbone_rgb:
  name: 'TimmWrapper'
  params:
    model_name: 'vit_small_patch16_dinov3'
    pretrained: true
  has_temporal: false
backbone_depth:
  name: 'TimmWrapper'
  params:
    model_name: 'vit_small_patch16_dinov3'
    pretrained: true
  has_temporal: false
backbone_lidar:
  name: 'P4TEncoder'
  params:
    radius: 0.7
    nsamples: 32
    spatial_stride: 8
    temporal_kernel_size: 3
    temporal_stride: 1
    emb_relu: false
    dim: 512
    depth: 5
    heads: 8
    dim_head: 64
    mlp_dim: 1024
    features: 3
    mode: 'xyz'
  has_temporal: true
backbone_mmwave:
  name: 'P4TEncoder'
  params:
    radius: 0.7
    nsamples: 32
    spatial_stride: 8
    temporal_kernel_size: 3
    temporal_stride: 1
    emb_relu: false
    dim: 512
    depth: 5
    heads: 8
    dim_head: 64
    mlp_dim: 1024
    features: 2
    mode: 'all'
  has_temporal: true
# --------------------------------------
# Aggregator V3 - Improved architecture
# --------------------------------------
aggregator:
  name: 'TransformerAggregatorV3'
  params:
    input_dims: [384, 384, 512, 512]  # RGB, Depth, LiDAR, mmWave
    embed_dim: 256  # Increased from 256 for more capacity
    num_register_tokens: 4
    depth: 6  # Deeper network for better feature learning
    num_heads: 8
    skeleton_type: 'mmfi'
    # Architecture control flags
    use_parallel_paths: true        # Enable parallel multi-path processing
    use_dynamic_fusion: true        # Enable uncertainty-aware modality fusion
    use_skeleton_guidance: true     # Enable skeleton-guided attention
    use_fpn_output: false           # Enable FPN-style multi-scale output
    use_grad_ckpt: false           # Set to true to save memory if needed
    max_spatial_seq_len: 1000
    max_temporal_seq_len: 243
# --------------------------------------
# Prediction Head V3 - Advanced head
# --------------------------------------
# keypoint_head:
#   name: 'RegressionKeypointHeadV3'
#   params:
#     emb_size: 256  # Match aggregator embed_dim
#     use_multi_scale: true              # Use multi-scale features from FPN
#     use_modality_attention: true       # Learn modality importance weights
#     temporal_strategy: 'attention'     # Options: 'mean', 'max', 'last', 'attention', 'conv'
#     estimate_uncertainty: true         # Estimate per-joint uncertainty
#     dropout: 0.1                       # Dropout for regularization
#     losses:
#       - name: 'MSELoss'
#         params: null
#         weight: 1.0
#       - name: 'L1Loss'  # Additional L1 loss for robustness
#         params: null
#         weight: 0.5
# --------------------------------------
# Alternative: Simplified Head (for quick experiments)
# --------------------------------------
keypoint_head:
  name: 'RegressionKeypointHeadV3Simple'
  params:
    emb_size: 256
    dropout: 0.1
    losses:
      - name: 'MSELoss'
        params: null
        weight: 1.0
# --------------------------------------
# Metrics parameters
# --------------------------------------
metrics:
  - name: 'MPJPE'
    params:
      affix: null
  - name: 'PAMPJPE'
    params:
      affix: null
# --------------------------------------
# Augmentation parameters
# --------------------------------------
train_pipeline: &train_pipeline
  # - name: VideoResize
  #   params:
  #     size: [192, 256]
  #     keys: ['input_rgb', 'input_depth']
  - name: VideoNormalize
    params:
      norm_mode: 'imagenet'
      keys: ['input_rgb']
  - name: VideoNormalize
    params:
      norm_mode: 'zero_one'
      keys: ['input_depth']
  - name: PCPad
    params:
      num_points: 1024
      pad_mode: 'repeat'
      keys: ['input_lidar']
  - name: PCPad
    params:
      num_points: 256
      pad_mode: 'repeat'
      keys: ['input_mmwave']
  - name: ToTensor
    params: null
val_pipeline: *train_pipeline
test_pipeline: *train_pipeline

vis_denorm_params:
  rgb_mean: [123.675, 116.28, 103.53]
  rgb_std: [58.395, 57.12, 57.375]
  depth_mean: [0.0, 0.0, 0.0]
  depth_std: [255.0, 255.0, 255.0]

# --------------------------------------
# Additional training configurations
# --------------------------------------
# Uncomment to enable gradient checkpointing for memory savings
# aggregator:
#   params:
#     use_grad_ckpt: true

# Uncomment to try different configurations
# Alternative 1: Disable some V3 features for ablation study
# aggregator:
#   params:
#     use_parallel_paths: false
#     use_dynamic_fusion: false
#     use_skeleton_guidance: true
#     use_fpn_output: false

# Alternative 2: Lighter model for faster training
# aggregator:
#   params:
#     embed_dim: 256
#     depth: 8
#     num_heads: 4
# keypoint_head:
#   params:
#     emb_size: 256
