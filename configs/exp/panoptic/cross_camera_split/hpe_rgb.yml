strategy: ddp
benchmark: true
deterministic: false
pretrained: false
sync_batchnorm: false
clip_grad: null
precision: 16
epochs: &epochs 20
# --------------------------------------
# Dataset parameters
# --------------------------------------
train_dataset:
  name: 'PanopticPreprocessedDatasetV1'
  params:
    data_root: &data_root '/opt/data/panoptic_kinoptic_single_actor_cropped'
    unit: 'm'
    gt_unit: 'cm'
    output_num_joints: 19
    apply_to_new_world: true
    remove_root_rotation: true
    modality_names: ['rgb']
    rgb_cameras: ['kinect_001', 'kinect_002', 'kinect_003', 'kinect_004', 'kinect_005', 'kinect_006', 'kinect_007', 'kinect_008', 'kinect_009', 'kinect_010']
    depth_cameras: ['kinect_001', 'kinect_002', 'kinect_003', 'kinect_004', 'kinect_005', 'kinect_006', 'kinect_007', 'kinect_008', 'kinect_009', 'kinect_010']
    convert_depth_to_lidar: true
    split: 'train'
    split_config: 'configs/datasets/panoptic_split_config.yml'
    split_to_use: 'cross_camera_split'
    test_mode: false
    seq_len: 1
    seq_step: 1
    pad_seq: true
    causal: true
    use_all_pairs: false
    colocated: false
    sequence_allowlist: &sequence_allowlist ["171026_pose1", "171026_pose2", "171204_pose3", "171204_pose4"]
    strict_validation: true
    apply_to_new_world: true
    remove_root_rotation: true
    root_rotation_fallback: 'skip'
    max_skip_invalid_samples: 256
val_dataset:
  name: 'PanopticPreprocessedDatasetV1'
  params:
    data_root: *data_root
    unit: 'm'
    gt_unit: 'cm'
    output_num_joints: 19
    apply_to_new_world: true
    remove_root_rotation: true
    modality_names: ['rgb']
    rgb_cameras: ['kinect_001', 'kinect_002', 'kinect_003', 'kinect_004', 'kinect_005', 'kinect_006', 'kinect_007', 'kinect_008', 'kinect_009', 'kinect_010']
    depth_cameras: ['kinect_001', 'kinect_002', 'kinect_003', 'kinect_004', 'kinect_005', 'kinect_006', 'kinect_007', 'kinect_008', 'kinect_009', 'kinect_010']
    convert_depth_to_lidar: true
    split: 'test'
    split_config: 'configs/datasets/panoptic_split_config.yml'
    split_to_use: 'cross_camera_split'
    test_mode: true
    seq_len: 1
    seq_step: 1
    pad_seq: true
    causal: true
    use_all_pairs: false
    colocated: false
    sequence_allowlist: *sequence_allowlist
    strict_validation: true
    apply_to_new_world: true
    remove_root_rotation: true
    root_rotation_fallback: 'skip'
    max_skip_invalid_samples: 256
test_dataset:
  name: 'PanopticPreprocessedDatasetV1'
  params:
    data_root: *data_root
    unit: 'm'
    gt_unit: 'cm'
    output_num_joints: 19
    apply_to_new_world: true
    remove_root_rotation: true
    modality_names: ['rgb']
    rgb_cameras: ['kinect_001', 'kinect_002', 'kinect_003', 'kinect_004', 'kinect_005', 'kinect_006', 'kinect_007', 'kinect_008', 'kinect_009', 'kinect_010']
    depth_cameras: ['kinect_001', 'kinect_002', 'kinect_003', 'kinect_004', 'kinect_005', 'kinect_006', 'kinect_007', 'kinect_008', 'kinect_009', 'kinect_010']
    convert_depth_to_lidar: true
    split: 'test'
    split_config: 'configs/datasets/panoptic_split_config.yml'
    split_to_use: 'cross_camera_split'
    test_mode: true
    seq_len: 1
    seq_step: 1
    pad_seq: true
    causal: true
    use_all_pairs: false
    colocated: false
    sequence_allowlist: *sequence_allowlist
    strict_validation: true
    apply_to_new_world: true
    remove_root_rotation: true
    root_rotation_fallback: 'skip'
    max_skip_invalid_samples: 256
# --------------------------------------
# Optimizer parameters
# --------------------------------------
optim_name: AdamW
optim_params:
  lr: &lr 0.00005
  weight_decay: 0.00001
# --------------------------------------
# Learning rate scheduler parameters
# --------------------------------------
sched_name: LinearWarmupCosineAnnealingLR
sched_params:
  warmup_epochs: 4
  max_epochs: *epochs
  warmup_start_lr: 0.000005
  eta_min: 0.000005
# --------------------------------------
# Model parameters
# --------------------------------------
model_name: HummanVIBEToken
backbone_rgb:
  name: 'TimmWrapper'
  params:
    model_name: 'vit_small_patch16_dinov3'
    pretrained: true
  has_temporal: false
aggregator:
  name: 'TransformerAggregatorV4'
  params:
    input_dims: [384, 384, 512, 512]
    embed_dim: 512
    num_register_tokens: 4
    num_smpl_tokens: 1
    aa_order: ['single', 'cross_joint', 'gcn']
    aa_block_size: 1
    depth: 12
    block_type: 'Block'
    skeleton_type: 'smpl'
    num_heads: 8
    mlp_ratio: 2.0
    qkv_bias: true
    proj_bias: true
    ffn_bias: true
    qk_norm: true
    init_values: 0.01
keypoint_head:
  name: 'RegressionKeypointHeadV5'
  params:
    emb_size: 1024
    num_joints: 19
    num_register_tokens: 4
    num_smpl_tokens: 1
    max_modalities: 4
    last_n_layers: 4
    pose_encoding_type: "absT_quaR_FoV"
    losses:
      - name: 'KeypointLoss'
        params:
          loss_type: 'MSE'
        weight: 1.0
        alias: 'KeypointMSELoss'
# --------------------------------------
# Metrics parameters
# --------------------------------------
metrics:
  - name: 'MPJPE'
    params:
      use_smpl: false
      root_joint_idx: 0
  - name: 'PAMPJPE'
    params:
      use_smpl: false
      root_joint_idx: 0
# --------------------------------------
# Augmentation parameters
# --------------------------------------
train_pipeline: &train_pipeline
  - name: CameraParamToPoseEncoding
    params:
      pose_encoding_type: "absT_quaR_FoV"
  - name: VideoNormalize
    params:
      norm_mode: 'imagenet'
      keys: ['input_rgb']
  - name: ToTensor
    params: null
val_pipeline: *train_pipeline
test_pipeline: *train_pipeline
vis_skl_format: 'panoptic_coco19'
vis_denorm_params:
  rgb_mean: [123.675, 116.28, 103.53]
  rgb_std: [58.395, 57.12, 57.375]
  depth_mean: [0.0]
  depth_std: [255.0]
