strategy: ddp
benchmark: true
deterministic: false
pretrained: false
sync_batchnorm: false
clip_grad: null
precision: 16
epochs: &epochs 20
monitor: 'val_mpjpe'
monitor_mode: 'min'
# --------------------------------------
# Dataset parameters
# --------------------------------------
train_dataset:
  name: 'PanopticPreprocessedDatasetV1'
  params:
    data_root: &data_root '/opt/data/panoptic_kinoptic_single_actor_cropped'
    unit: 'm'
    gt_unit: 'cm'
    output_num_joints: 19
    modality_names: ['rgb', 'depth']
    rgb_cameras: ['kinect_001', 'kinect_002', 'kinect_003', 'kinect_004', 'kinect_005', 'kinect_006', 'kinect_007', 'kinect_008', 'kinect_009', 'kinect_010']
    depth_cameras: ['kinect_001', 'kinect_002', 'kinect_003', 'kinect_004', 'kinect_005', 'kinect_006', 'kinect_007', 'kinect_008', 'kinect_009', 'kinect_010']
    convert_depth_to_lidar: true
    split: 'train'
    split_config: 'configs/datasets/panoptic_split_config.yml'
    split_to_use: 'cross_camera_split'
    test_mode: false
    seq_len: 1
    seq_step: 1
    pad_seq: true
    causal: true
    use_all_pairs: false
    colocated: false
    sequence_allowlist: &sequence_allowlist ["171026_pose1", "171026_pose2", "171204_pose1", "171204_pose2", "171204_pose3", "171204_pose4", "171204_pose5", "171204_pose6"]
    strict_validation: true
val_dataset:
  name: 'PanopticPreprocessedDatasetV1'
  params:
    data_root: *data_root
    unit: 'm'
    gt_unit: 'cm'
    output_num_joints: 19
    modality_names: ['rgb', 'depth']
    rgb_cameras: ['kinect_001', 'kinect_002', 'kinect_003', 'kinect_004', 'kinect_005', 'kinect_006', 'kinect_007', 'kinect_008', 'kinect_009', 'kinect_010']
    depth_cameras: ['kinect_001', 'kinect_002', 'kinect_003', 'kinect_004', 'kinect_005', 'kinect_006', 'kinect_007', 'kinect_008', 'kinect_009', 'kinect_010']
    convert_depth_to_lidar: true
    split: 'test'
    split_config: 'configs/datasets/panoptic_split_config.yml'
    split_to_use: 'cross_camera_split'
    test_mode: true
    seq_len: 1
    seq_step: 1
    pad_seq: true
    causal: true
    use_all_pairs: false
    colocated: false
    sequence_allowlist: *sequence_allowlist
    strict_validation: true
test_dataset:
  name: 'PanopticPreprocessedDatasetV1'
  params:
    data_root: *data_root
    unit: 'm'
    gt_unit: 'cm'
    output_num_joints: 19
    modality_names: ['rgb', 'depth']
    rgb_cameras: ['kinect_001', 'kinect_002', 'kinect_003', 'kinect_004', 'kinect_005', 'kinect_006', 'kinect_007', 'kinect_008', 'kinect_009', 'kinect_010']
    depth_cameras: ['kinect_001', 'kinect_002', 'kinect_003', 'kinect_004', 'kinect_005', 'kinect_006', 'kinect_007', 'kinect_008', 'kinect_009', 'kinect_010']
    convert_depth_to_lidar: true
    split: 'test'
    split_config: 'configs/datasets/panoptic_split_config.yml'
    split_to_use: 'cross_camera_split'
    test_mode: true
    seq_len: 1
    seq_step: 1
    pad_seq: true
    causal: true
    use_all_pairs: false
    colocated: false
    sequence_allowlist: *sequence_allowlist
    strict_validation: true
# --------------------------------------
# Optimizer parameters
# --------------------------------------
optim_name: AdamW
optim_params:
  lr: &lr 0.0001
  weight_decay: 0.00001
# --------------------------------------
# Learning rate scheduler parameters
# --------------------------------------
sched_name: LinearWarmupCosineAnnealingLR
sched_params:
  warmup_epochs: 2
  max_epochs: *epochs
  warmup_start_lr: 0.00001
  eta_min: 0.00001
# --------------------------------------
# Model parameters
# --------------------------------------
model_name: PanopticHPE
backbone_rgb:
  name: 'ResNet18'
  params:
    pretrained: false
  has_temporal: false
backbone_lidar:
  name: 'MAMBA4DEncoder'
  params:
    radius: 0.1
    nsamples: 16
    spatial_stride: 32
    temporal_kernel_size: 3
    temporal_stride: 1
    emb_relu: false
    dim: 512
    mlp_dim: 1024
    num_classes: 0
    depth_mamba_inter: 5
    rms_norm: true
    drop_out_in_block: 0.0
    drop_path: 0.1
    depth_mamba_intra: 1
    intra: true
    mode: 'xyz'
  has_temporal: true
aggregator:
  name: 'SimpleAggregator'
  params:
    input_dims: [512, null, 512, null]
    embed_dim: 256
keypoint_head:
  name: 'RegressionKeypointHead'
  params:
    emb_size: 256
    num_classes: 57
    losses:
      - name: 'MSELoss'
        params: null
        weight: 1.0
        alias: 'KeypointMSELoss'
# --------------------------------------
# Metrics parameters
# --------------------------------------
metrics:
  - name: 'MPJPE'
    params:
      use_smpl: false
      root_joint_idx: 0
  - name: 'PAMPJPE'
    params:
      use_smpl: false
      root_joint_idx: 0
# --------------------------------------
# Augmentation parameters
# --------------------------------------
train_pipeline: &train_pipeline
  - name: VideoNormalize
    params:
      norm_mode: 'imagenet'
      keys: ['input_rgb']
  - name: PCPad
    params:
      num_points: 1024
      pad_mode: 'repeat'
      keys: ['input_lidar']
  - name: ToTensor
    params: null
val_pipeline: *train_pipeline
test_pipeline: *train_pipeline
vis_skl_format: 'panoptic_coco19'
vis_denorm_params:
  rgb_mean: [123.675, 116.28, 103.53]
  rgb_std: [58.395, 57.12, 57.375]
  depth_mean: [0.0]
  depth_std: [255.0]
